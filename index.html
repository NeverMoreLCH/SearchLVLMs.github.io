<!DOCTYPE html>
<html>
<head>
  <title>MMIU</title>
    <style>
        .hidden {
            display: none;
        }
    </style>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://kit.fontawesome.com/f8ddf9854a.js" crossorigin="anonymous"></script>
  <meta charset="utf-8">
  <meta name="description"
        content="Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models">
  <meta name="keywords" content="MMIU, LVLM, LVLM Evaluation, multiple images, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> MMIU: Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/question_card.js"></script>
  <script src="./data/results/data_setting.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>
  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/OpenGVLab/Multi-Modality-Arena">
            <b>Lvlm-ehub</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
          <a class="navbar-item" href="https://github.com/OpenGVLab/MMT-Bench">
            <b>MMT-Bench</b> <p style="font-size:18px; display: inline; margin-left: 5px;">üî•</p>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <span class="MMIU" style="vertical-align: middle">MMIU</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models
          </h2>
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block">Xiang Yue*<sup style="color:#6fbf73;">‚Ä†,1</sup>,</span> -->
            <span class="author-block">
              Fanqing Meng<sup>*,</sup><sup style="color:#ffac33;">2</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
            </span>
            <!-- <span class="author-block">Yuansheng Ni*<sup style="color:#ffac33;">2</sup>,</span> -->
            <span class="author-block">
              Jin Wang<sup>*,</sup><sup style="color:#ed4b82;">3</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
            </span>
            <span class="author-block">
              Chuanhao Li<sup>*,</sup><sup style="color:#6fbf73;">1</sup></a>,
            </span>
            <!-- <span class="author-block">Kai Zhang*<sup style="color:#ed4b82;">3</sup>,</span> -->
            <span class="author-block">Quanfeng Lu<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Hao Tian<sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Jiaqi Liao<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Xizhou Zhu<sup style="color:#9b51e0;">5</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Jifeng Dai<sup style="color:#9b51e0;">5</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Yu Qiao<sup style="color:#6fbf73;">1</sup>,</span>
            <!-- <span class="author-block">Huan Sun*<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Yu Su*<sup style="color:#ed4b82;">‚Ä†,3</sup>,</span>
            <span class="author-block">Wenhu Chen*<sup style="color:#ffac33;">‚Ä†,2</sup></span> -->
            <span class="author-block">
              Ping Luo<sup style="color:#ed4b82;">3</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
          </span>
          <span class="author-block">
              Kaipeng Zhang<sup>‚Ä†,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
          </span>
          <span class="author-block">
              Wenqi Shao<sup>‚Ä†,</sup><sup style="color:#6fbf73;">1</sup></a>
              
          </span>
          
          </div>
          
          <br>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>OpenGVLab, Shanghai AI Laboratory,</span>
            <span class="author-block"><sup style="color:#ffac33;">2</sup>Shanghai Jiao Tong University,</span></br>
            <span class="author-block"><sup style="color:#ed4b82;">3</sup>The University of Hong Kong,</span>
            <span class="author-block"><sup style="color:#007bff;">4</sup>SenseTime Research,</span>
            <span class="author-block"><sup style="color:#9b51e0;">5</sup>Tsinghua University</span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution</span><br>
            <span class="author-block">‚Ä†Corresponding Author:</span>
            <span class="author-block"><a href="mailto:shaowenqi@pjlab.org.cn">shaowenqi@pjlab.org.cn</a>,</span>
            <span class="author-block"><a href="mailto:zhangkaipeng@pjlab.org.cn">zhangkaipeng@pjlab.org.cn</a></span>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/pdf/2408.02718"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/FanqingM/MMIU-Benchmark"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ü§ó</p>
                      <!-- üîó -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/OpenGVLab/MMIU"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-trophy"></i>
                      <!-- <p style="font-size:18px">üèÜ</p> -->
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
              <!-- EvalAI Link. -->
              <span class="link-block">
                <a href="#examples"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-book"></i>
                  </span>
                  <span>Examples</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<style>
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }
</style>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body">
      <img src="static/images/tease_scores.png" alt="Examples from the dataset"/>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div> -->
      <!-- <div class="box m-5"> -->
        <div class="content has-text-centered">
          <img src="static/images/MMeval_plot.jpg" alt="MMIU" width="100%"/>
          <p>Visualization of MMIU. Our MMIU contains 77,659 images, 7 types of image relationships, and 5 image modalities, along with 11,698 multiple-choice questions, providing a comprehensive evaluation for 52 multi-image understanding tasks. Each example comes from a task chosen from each multi-image relationship. We construct MMIU by adopting a top-down hierarchy where image relationships of interest are enumerated and multiple tasks are associated with each relationship. The number of tasks for each relationship is demoted.</p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üîîNews</h2>
        <div class="content has-text-justified">
          <p>
            <b>üî•[2024-08-07] We released the <a href="https://arxiv.org/abs/2408.02718">technical report</a>.</b>
          </p>
      </div>      
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            The capability to process multiple images is crucial for Multimodal Large Language Models, as a single image captures information from a specific angle and moment, limiting the model's ability to understand and reason about the entire scene. Recent multi-image Multimodal Large Language Models (MLLMs) have begun to address this need. However, their evaluation has not kept pace with their development. To fill this gap, we introduce the Multimodal Multi-image Understanding (MMIU) benchmark, a comprehensive evaluation suite designed to assess MLLMs across a wide range of multi-image tasks. MMIU encompasses 7 types of multi-image relationships, 52 tasks, 77K images, and 11K meticulously curated multiple-choice questions, making it the most extensive benchmark of its kind. Our evaluation of 24 popular MLLMs, including both open-source and proprietary models, reveals significant challenges in multi-image comprehension, particularly in tasks involving spatial understanding. Even the most advanced models, such as GPT-4o, achieve only 55.7% accuracy on MMIU. Through multi-faceted analytical experiments, we identify key performance gaps and limitations, providing valuable insights for future model and data improvements. We aim for MMIU to advance the frontier of LVLM research and development, moving us toward achieving sophisticated multimodal multi-image user interactions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 MMIU">
    <span class="MMIU" style="vertical-align: middle">MMIU</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="static/images/MMeval_construct.jpg" alt="pipeline" class="center">
          <br>
          <p>
            An illustration of our data collection process. First, we refine multi-image tasks and collect task data based on cognitive psychology. Then, we standardize these datasets into a uniform format‚Äîmetadata. Next, we generate multiple-choice samples with answerable and unanswerable questions from the metadata using either manually designed rules or GPT4o. Our benchmarks include capability evaluations across various image types.
          </p>
        </div>
    </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparisons with Existing Benchmarks</h2>
        <div class="content has-text-justified">
          <p>
            The comparison between MMIU and existing multi-image evaluation benchmarks including Video-MME, MIRB, MUIRBENCH, and MileBench. We summarize the image relationships in previous benchmarks according to seven categories defined in MMIU. `Y\&N' indicates that our MMIU comprises both answerable and unanswerable questions. I, T, V, D and P represent image, text, video, depth map and point cloud, respectively. Compared with prior datasets, MMIU involves massive test samples spanning 52 multimodal tasks and 5 modalities, and comprehensive multi-image analyses by image relationships, task map and supervised fine-tuning (SFT). 
        </p>
        <img src="static/images/compare.png" alt="comparison" class="center">
        </div>
    </div>
    </div>
  </div>
</section>

<style>
  .image-row {
      display: center; /* Use flexbox layout */
  }
  .image-row img {
      width: 40%; /* Each image takes up 50% of the width */
  }
</style>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 MMT-Bench">Experiment Results</h1>
  </div>
</section>
<section class="section">
  <div class="container">
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <div class="content has-text-justified">
            <p>
              Quantitative results for 24 LVLMs across 52 tasks are summarized. Accuracy is the metric, and the Overall score is computed across all tasks.  The maximum value of each task is bolded. Notice that although InternVL1.5-chat supports multiple image inputs, its training phase did not incorporate multi-image data. The full term of task abbreviation can be found in the paper.
            </p>
          </div>

          <div class="model-labels-container">
            <!-- <span class="leaderboard-label" style="background-color: #f8fffe;">Open-Source</span>
            <span class="leaderboard-label" style="background-color: #f9f2f8;">Closed</span> -->
            <span class="leaderboard-label" style="background-color: rgba(255, 208, 80, 0.15);">Baseline</span>
            <span class="leaderboard-label" style="background-color: rgba(249, 242, 248, 1);">Adequate Multi-Image SFT LVLMs</span>
            <span class="leaderboard-label" style="background-color: rgb(229, 237, 255);">Multi-Image input LVLMs</span>
            <span class="leaderboard-label" style="background-color: rgb(224, 243, 224);">Single-Image input LVLMs</span>
            <span class="leaderboard-label" style="background-color: rgba(117, 209, 215, 0.1);">Closed-source LVLMs</span>
          </div>
        <style>
            .table-container {
              display: flex; /* Enables Flexbox layout */
          }
        </style>
          <table class="table-container">
            <tr style="background-color: rgba(122, 122, 122, 0.15);">
                <td class="js-sort-number" style="text-align: left;"><strong>Model</strong></td>
                <td class="js-sort-number"><strong>Overall</strong></td>
                <td class="js-sort-number"><strong>CR</strong></td>
                <td class="js-sort-number"><strong>ER</strong></td>
                <td class="js-sort-number"><strong>FD</strong></td>
                <td class="js-sort-number"><strong>FC</strong></td>
                <td class="js-sort-number"><strong>SC</strong></td>
                <td class="js-sort-number"><strong>VCor</strong></td>
                <td class="js-sort-number"><strong>VQA</strong></td>
                <td class="js-sort-number"><strong>VGR</strong></td>
                <td class="js-sort-number"><strong>FR</strong></td>
                <td class="js-sort-number"><strong>HR</strong></td>
                <td class="js-sort-number"><strong>I2IR</strong></td>
                <td class="js-sort-number"><strong>MIC</strong></td>
                <td class="js-sort-number"><strong>PR</strong></td>
                <td class="js-sort-number"><strong>S2IR</strong></td>
                <td class="js-sort-number"><strong>STD</strong></td>
                <td class="js-sort-number"><strong>STS</strong></td>
                <td class="js-sort-number"><strong>T2IR</strong></td>
                <td class="js-sort-number"><strong>VR</strong></td>
                <td class="js-sort-number"><strong>AQA</strong></td>
                <td class="js-sort-number"><strong>GAR</strong></td>
                <td class="js-sort-number"><strong>MVU</strong></td>
                <td class="js-sort-number"><strong>MEV</strong></td>
                <td class="js-sort-number"><strong>NIP</strong></td>
                <td class="js-sort-number"><strong>TL</strong></td>
                <td class="js-sort-number"><strong>TO</strong></td>
                <td class="js-sort-number"><strong>VidCap</strong></td>
            </tr>
            <tr style="background-color: rgba(122, 122, 122, 0.15);">
              <td></td>
              <td></td>
              <td class="js-sort-number"><strong>GuAR</strong></td>
              <td class="js-sort-number"><strong>GNAP</strong></td>
              <td class="js-sort-number"><strong>TC</strong></td>
              <td class="js-sort-number"><strong>VClz</strong></td>
              <td class="js-sort-number"><strong>VCo</strong></td>
              <td class="js-sort-number"><strong>VO</strong></td>
              <td class="js-sort-number"><strong>EVQA</strong></td>
              <td class="js-sort-number"><strong>HE</strong></td>
              <td class="js-sort-number"><strong>IQASC</strong></td>
              <td class="js-sort-number"><strong>ICSC</strong></td>
              <td class="js-sort-number"><strong>ISTE</strong></td>
              <td class="js-sort-number"><strong>ITRSC</strong></td>
              <td class="js-sort-number"><strong>MAR</strong></td>
              <td class="js-sort-number"><strong>MR</strong></td>
              <td class="js-sort-number"><strong>JPS</strong></td>
              <td class="js-sort-number"><strong>3DE</strong></td>
              <td class="js-sort-number"><strong>3DOD</strong></td>
              <td class="js-sort-number"><strong>3DOT</strong></td>
              <td class="js-sort-number"><strong>3DPE</strong></td>
              <td class="js-sort-number"><strong>3DSR</strong></td>
              <td class="js-sort-number"><strong>3DQA</strong></td>
              <td class="js-sort-number"><strong>PT</strong></td>
              <td class="js-sort-number"><strong>RPM</strong></td>
              <td class="js-sort-number"><strong>SOT</strong></td>
              <td class="js-sort-number"><strong>3DCR</strong></td>
              <td class="js-sort-number"><strong>3DIR</strong></td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td style="text-align: left;"><strong>Frequency</strong></td>
                <td>31.5</td>
                <td>32.0</td>
                <td>27.7</td>
                <td>27.3</td>
                <td>30.0</td>
                <td>30.2</td>
                <td>29.6</td>
                <td>49.0</td>
                <td>76.5</td>
                <td>29.0</td>
                <td>28.0</td>
                <td>27.5</td>
                <td>29.0</td>
                <td>30.0</td>
                <td>37.0</td>
                <td>51.5</td>
                <td>50.0</td>
                <td>26.5</td>
                <td>31.0</td>
                <td>32.0</td>
                <td>30.0</td>
                <td>29.0</td>
                <td>30.0</td>
                <td>28.5</td>
                <td>30.1</td>
                <td>29.0</td>
                <td>27.5</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td></td>
              <td></td>
              <td>31.5</td>
              <td>28.0</td>
              <td>28.5</td>
              <td>27.5</td>
              <td>30.5</td>
              <td>31.0</td>
              <td>27.5</td>
              <td>27.5</td>
              <td>41.5</td>
              <td>27.5</td>
              <td>30.0</td>
              <td>18.0</td>
              <td>27.6</td>
              <td>55.6</td>
              <td>29.0</td>
              <td>26.5</td>
              <td>29.0</td>
              <td>28.0</td>
              <td>26.5</td>
              <td>28.5</td>
              <td>29.5</td>
              <td>30.5</td>
              <td>18.0</td>
              <td>28.0</td>
              <td>26.0</td>
              <td>27.0</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
                <td style="text-align: left;"><strong>Random</strong></td>
                <td>27.4</td>
                <td>19.0</td>
                <td>23.0</td>
                <td>22.3</td>
                <td>26.4</td>
                <td>24.7</td>
                <td>29.1</td>
                <td>45.0</td>
                <td>50.0</td>
                <td>23.0</td>
                <td>26.0</td>
                <td>24.0</td>
                <td>20.0</td>
                <td>24.5</td>
                <td>37.5</td>
                <td>51.0</td>
                <td>55.0</td>
                <td>27.5</td>
                <td>28.0</td>
                <td>28.0</td>
                <td>26.5</td>
                <td>24.0</td>
                <td>27.5</td>
                <td>23.0</td>
                <td>26.9</td>
                <td>24.5</td>
                <td>23.0</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td></td>
              <td></td>
              <td>21.0</td>
              <td>12.5</td>
              <td>24.0</td>
              <td>27.5</td>
              <td>20.5</td>
              <td>27.0</td>
              <td>32.0</td>
              <td>31.5</td>
              <td>38.5</td>
              <td>27.0</td>
              <td>26.0</td>
              <td>14.0</td>
              <td>24.6</td>
              <td>50.4</td>
              <td>23.5</td>
              <td>25.5</td>
              <td>24.5</td>
              <td>22.5</td>
              <td>31.0</td>
              <td>23.5</td>
              <td>24.5</td>
              <td>25.5</td>
              <td>10.5</td>
              <td>22.5</td>
              <td>27.0</td>
              <td>27.0</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td style="text-align: left;">
                <a href="https://openai.com/index/hello-gpt-4o/">
                  <b>GPT-4o</b>
               </a>
              </td>
              <td><b>55.7</b></td>
              <td>67.8</td>
              <td><b>46.5</b></td>
              <td><b>88.8</b></td>
              <td><b>42.6</b></td>
              <td><b>41.5</b></td>
              <td><b>72.6</b></td>
              <td>79.2</td>
              <td>61.3</td>
              <td>76.0</td>
              <td>42.0</td>
              <td>59.5</td>
              <td><b>93.5</b></td>
              <td>61.5</td>
              <td>67.0</td>
              <td>11.0</td>
              <td><b>84.0</b></td>
              <td><b>70.5</b></td>
              <td>68.0</td>
              <td>33.5</td>
              <td><b>91.5</b></td>
              <td>71.5</td>
              <td><b>35.0</b></td>
              <td>26.5</td>
              <td><b>50.8</b></td>
              <td><b>28.0</b></td>
              <td><b>92.5</b></td>
          </tr>
          <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td></td>
              <td></td>
              <td>78.0</td>
              <td>46.5</td>
              <td><b>62.5</b></td>
              <td><b>43.5</b></td>
              <td><b>97.5</b></td>
              <td>21.5</td>
              <td>57.5</td>
              <td><b>29.5</b></td>
              <td>88.0</td>
              <td>58.5</td>
              <td><b>35.0</b></td>
              <td>17.5</td>
              <td><b>81.9</b></td>
              <td>46.6</td>
              <td>23.5</td>
              <td>24.0</td>
              <td>40.5</td>
              <td><b>94.5</b></td>
              <td>85.0</td>
              <td>22.0</td>
              <td>39.0</td>
              <td>55.0</td>
              <td>12.5</td>
              <td>56.0</td>
              <td><b>69.0</b></td>
              <td><b>49.0</b></td>
          </tr>
          <tr style="background-color: rgba(117, 209, 215, 0.1);">
            <td style="text-align: left;">
              <a href="https://www.gemini-ai.org/gemini-pro-1-5/">
                <b>Gemini1.5</b>
             </a>
            </td>
            <td>53.4</td>
            <td>71.0</td>
            <td>31.8</td>
            <td>73.5</td>
            <td>24.3</td>
            <td>34.9</td>
            <td>47.3</td>
            <td>78.8</td>
            <td>61.0</td>
            <td>88.0</td>
            <td><b>80.0</b></td>
            <td>74.0</td>
            <td>89.0</td>
            <td>70.5</td>
            <td><b>81.5</b></td>
            <td>74.0</td>
            <td>80.0</td>
            <td>60.5</td>
            <td>68.0</td>
            <td><b>35.5</b></td>
            <td>88.0</td>
            <td><b>75.0</b></td>
            <td>25.0</td>
            <td>21.0</td>
            <td>45.6</td>
            <td>26.5</td>
            <td>84.0</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
            <td></td>
            <td></td>
            <td><b>93.0</b></td>
            <td>39.5</td>
            <td>59.0</td>
            <td>30.0</td>
            <td>60.0</td>
            <td><b>43.5</b></td>
            <td>53.5</td>
            <td>22.5</td>
            <td><b>91.0</b></td>
            <td><b>64.5</b></td>
            <td>24.0</td>
            <td>13.0</td>
            <td>68.8</td>
            <td>51.1</td>
            <td><b>34.5</b></td>
            <td>20.0</td>
            <td>32.0</td>
            <td>48.5</td>
            <td>37.5</td>
            <td>28.5</td>
            <td>35.5</td>
            <td>66.5</td>
            <td>13.0</td>
            <td>61.0</td>
            <td>55.0</td>
            <td>43.0</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
          <td style="text-align: left;">
            <a href="https://www.anthropic.com/news/claude-3-5-sonnet">
              <b>Claude3.5</b>
           </a>
          </td>
            <td>53.4</td>
            <td>70.2</td>
            <td>38.5</td>
            <td>76.6</td>
            <td>31.3</td>
            <td>34.9</td>
            <td>57.0</td>
            <td>77.8</td>
            <td>54.5</td>
            <td>92.0</td>
            <td>79.0</td>
            <td>62.0</td>
            <td>85.5</td>
            <td>77.5</td>
            <td>68.0</td>
            <td>80.0</td>
            <td>57.5</td>
            <td>65.5</td>
            <td>79.0</td>
            <td>26.0</td>
            <td>80.5</td>
            <td><b>75.0</b></td>
            <td>33.5</td>
            <td>10.5</td>
            <td>43.5</td>
            <td>23.0</td>
            <td>91.0</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
            <td></td>
            <td></td>
            <td>88.5</td>
            <td><b>55.0</b></td>
            <td>56.0</td>
            <td>26.5</td>
            <td>67.5</td>
            <td>38.5</td>
            <td>53.5</td>
            <td>23.0</td>
            <td>78.5</td>
            <td>52.0</td>
            <td>32.0</td>
            <td>4.0</td>
            <td>64.8</td>
            <td>42.1</td>
            <td>31.5</td>
            <td>23.5</td>
            <td><b>41.0</b></td>
            <td>32.0</td>
            <td><b>99.5</b></td>
            <td>21.5</td>
            <td>28.5</td>
            <td>78.5</td>
            <td>10.5</td>
            <td><b>67.5</b></td>
            <td>53.5</td>
            <td>36.5</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
        <td style="text-align: left;">
          <a href="https://www.gemini-ai.org/gemini-1-0/">
            <b>Gemini1.0</b>
         </a>
        </td>    
            <td>40.2</td>
            <td>63.2</td>
            <td>26.5</td>
            <td>36.6</td>
            <td>27.5</td>
            <td>28.3</td>
            <td>30.3</td>
            <td>60.8</td>
            <td><b>71.0</b></td>
            <td>25.0</td>
            <td>24.5</td>
            <td>28.0</td>
            <td>84.0</td>
            <td>21.0</td>
            <td>44.0</td>
            <td>71.0</td>
            <td>48.0</td>
            <td>27.0</td>
            <td>31.5</td>
            <td>34.5</td>
            <td>89.0</td>
            <td>73.5</td>
            <td>29.0</td>
            <td>21.5</td>
            <td>37.3</td>
            <td>23.5</td>
            <td>90.0</td>
        </tr>
        <tr style="background-color: rgba(117, 209, 215, 0.1);">
            <td></td>
            <td></td>
            <td>87.0</td>
            <td>35.5</td>
            <td><b>62.5</b></td>
            <td>24.5</td>
            <td>42.0</td>
            <td>23.0</td>
            <td>45.5</td>
            <td>17.0</td>
            <td>53.0</td>
            <td>55.0</td>
            <td>22.5</td>
            <td>16.0</td>
            <td>71.9</td>
            <td>43.6</td>
            <td>28.0</td>
            <td>22.0</td>
            <td>28.0</td>
            <td>36.0</td>
            <td>7.0</td>
            <td>24.5</td>
            <td>39.0</td>
            <td>17.0</td>
            <td>12.0</td>
            <td>47.0</td>
            <td>53.0</td>
            <td>33.5</td>
        </tr>
        <tr style="background-color: rgba(249, 242, 248, 1);">
          <td style="text-align: left;">
            <a href="https://arxiv.org/abs/2405.01483">
              <b>Mantis</b>
           </a>
          </td>    
            <td>45.6</td>
            <td>61.5</td>
            <td>31.8</td>
            <td>57.0</td>
            <td>24.3</td>
            <td>28.1</td>
            <td>30.9</td>
            <td>59.8</td>
            <td>65.2</td>
            <td>66.5</td>
            <td>54.0</td>
            <td>63.5</td>
            <td>71.0</td>
            <td>57.5</td>
            <td>64.5</td>
            <td>96.0</td>
            <td>65.5</td>
            <td>46.5</td>
            <td>70.5</td>
            <td>17.5</td>
            <td>81.0</td>
            <td>58.5</td>
            <td>28.5</td>
            <td>26.0</td>
            <td>23.8</td>
            <td>27.0</td>
            <td>85.0</td>
        </tr>
        <tr style="background-color: rgba(249, 242, 248, 1);">
            <td></td>
            <td></td>
            <td>73.5</td>
            <td>34.0</td>
            <td>51.5</td>
            <td>31.0</td>
            <td>14.0</td>
            <td>20.0</td>
            <td>54.5</td>
            <td>23.0</td>
            <td>66.0</td>
            <td>48.0</td>
            <td>23.5</td>
            <td>13.0</td>
            <td>71.4</td>
            <td>47.4</td>
            <td>27.5</td>
            <td>23.5</td>
            <td>24.0</td>
            <td>26.0</td>
            <td>22.5</td>
            <td>25.0</td>
            <td><b>50.5</b></td>
            <td>76.0</td>
            <td>13.5</td>
            <td>50.0</td>
            <td>59.0</td>
            <td>40.5</td>
        </tr>
        <tr style="background-color: rgba(249, 242, 248, 1);">
          <td style="text-align: left;">
            <a href="https://llava-vl.github.io/blog/2024-06-16-llava-next-interleave/">
              <b>Llava-interleave</b>
           </a>
          </td>  
            <td>32.4</td>
            <td>29.5</td>
            <td>24.8</td>
            <td>26.3</td>
            <td>23.2</td>
            <td>26.4</td>
            <td>25.1</td>
            <td>48.8</td>
            <td>49.8</td>
            <td>23.5</td>
            <td>25.0</td>
            <td>28.0</td>
            <td>57.0</td>
            <td>21.5</td>
            <td>33.0</td>
            <td>63.5</td>
            <td>54.5</td>
            <td>25.0</td>
            <td>26.0</td>
            <td>24.0</td>
            <td>27.0</td>
            <td>49.5</td>
            <td>29.0</td>
            <td>23.0</td>
            <td>25.4</td>
            <td>27.5</td>
            <td>32.5</td>
        </tr>
        <tr style="background-color: rgba(249, 242, 248, 1);">
            <td></td>
            <td></td>
            <td>43.0</td>
            <td>34.0</td>
            <td>49.0</td>
            <td>29.5</td>
            <td>32.0</td>
            <td>26.0</td>
            <td>30.0</td>
            <td>21.5</td>
            <td>42.0</td>
            <td>47.5</td>
            <td>22.5</td>
            <td>14.0</td>
            <td>23.6</td>
            <td>32.3</td>
            <td>17.5</td>
            <td><b>28.5</b></td>
            <td>23.0</td>
            <td>17.5</td>
            <td>3.0</td>
            <td>31.0</td>
            <td>36.0</td>
            <td><b>79.0</b></td>
            <td>15.0</td>
            <td>60.5</td>
            <td>34.5</td>
            <td>42.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://internvl.github.io/blog/2024-07-02-InternVL-2.0/">
              <b>InternVL2</b>
           </a>
          </td>   
            <td>50.3</td>
            <td><b>77.8</b></td>
            <td>41.5</td>
            <td>62.8</td>
            <td>24.6</td>
            <td>25.3</td>
            <td>35.3</td>
            <td><b>82.5</b></td>
            <td>59.8</td>
            <td><b>93.5</b></td>
            <td>47.0</td>
            <td><b>85.5</b></td>
            <td>92.5</td>
            <td><b>82.0</b></td>
            <td>73.0</td>
            <td>19.0</td>
            <td>77.0</td>
            <td>54.5</td>
            <td><b>83.5</b></td>
            <td>22.0</td>
            <td>86.5</td>
            <td>68.5</td>
            <td>33.0</td>
            <td>20.5</td>
            <td>26.9</td>
            <td>25.0</td>
            <td>88.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>91.5</td>
            <td>40.5</td>
            <td>52.0</td>
            <td>25.5</td>
            <td>78.0</td>
            <td>35.0</td>
            <td><b>63.0</b></td>
            <td>28.5</td>
            <td>77.5</td>
            <td>41.5</td>
            <td>26.0</td>
            <td><b>20.0</b></td>
            <td>78.4</td>
            <td><b>55.6</b></td>
            <td>27.5</td>
            <td>25.5</td>
            <td>28.0</td>
            <td>20.0</td>
            <td>26.0</td>
            <td><b>41.0</b></td>
            <td>43.0</td>
            <td>48.5</td>
            <td>13.5</td>
            <td>59.5</td>
            <td>51.5</td>
            <td>31.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5">
              <b>InternVL1.5-chat</b>
           </a>
          </td>   
            <td>37.4</td>
            <td>63.7</td>
            <td>31.0</td>
            <td>22.6</td>
            <td>20.3</td>
            <td>16.3</td>
            <td>28.3</td>
            <td>63.2</td>
            <td>38.5</td>
            <td>21.0</td>
            <td>28.0</td>
            <td>26.5</td>
            <td>82.5</td>
            <td>20.5</td>
            <td>31.5</td>
            <td>6.0</td>
            <td>45.5</td>
            <td>26.5</td>
            <td>29.5</td>
            <td>29.5</td>
            <td>85.0</td>
            <td>65.0</td>
            <td>32.0</td>
            <td>23.5</td>
            <td>29.0</td>
            <td>18.5</td>
            <td>89.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>90.5</td>
            <td>35.5</td>
            <td>56.5</td>
            <td>23.5</td>
            <td>31.0</td>
            <td>24.5</td>
            <td>53.0</td>
            <td>26.0</td>
            <td>40.0</td>
            <td>49.0</td>
            <td>25.5</td>
            <td>15.5</td>
            <td>59.3</td>
            <td>43.6</td>
            <td>19.5</td>
            <td>22.5</td>
            <td>23.5</td>
            <td>15.0</td>
            <td>33.5</td>
            <td>28.0</td>
            <td>39.0</td>
            <td>71.0</td>
            <td>9.5</td>
            <td>46.5</td>
            <td>50.5</td>
            <td>39.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/HuggingFaceM4/idefics2-8b">
              <b>idefics2-8b</b>
           </a>
          </td>  
            <td>27.8</td>
            <td>28.0</td>
            <td>25.8</td>
            <td>26.4</td>
            <td>26.7</td>
            <td>24.6</td>
            <td>28.6</td>
            <td>58.5</td>
            <td>30.8</td>
            <td>3.5</td>
            <td>9.5</td>
            <td>4.0</td>
            <td>82.0</td>
            <td>5.0</td>
            <td>27.5</td>
            <td><b>98.5</b></td>
            <td>70.5</td>
            <td>12.5</td>
            <td>7.0</td>
            <td>16.0</td>
            <td>24.5</td>
            <td>12.0</td>
            <td>19.0</td>
            <td>23.5</td>
            <td>22.3</td>
            <td>18.0</td>
            <td>19.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>23.5</td>
            <td>22.5</td>
            <td>21.0</td>
            <td>26.5</td>
            <td>21.5</td>
            <td>22.5</td>
            <td>14.5</td>
            <td>21.5</td>
            <td>31.0</td>
            <td>50.5</td>
            <td>25.5</td>
            <td>13.5</td>
            <td>15.1</td>
            <td><b>55.6</b></td>
            <td>27.5</td>
            <td>26.0</td>
            <td>21.5</td>
            <td>9.0</td>
            <td>21.5</td>
            <td>23.0</td>
            <td>11.5</td>
            <td>61.0</td>
            <td><b>18.0</b></td>
            <td>52.5</td>
            <td>44.5</td>
            <td>40.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/deepseek-ai/deepseek-vl-7b-base">
              <b>deepseek-vl-7b</b>
           </a>
          </td>  
            <td>24.6</td>
            <td>2.2</td>
            <td>22.2</td>
            <td>29.1</td>
            <td>23.3</td>
            <td>28.2</td>
            <td>29.0</td>
            <td>49.0</td>
            <td>65.5</td>
            <td>20.5</td>
            <td>25.0</td>
            <td>25.5</td>
            <td>72.5</td>
            <td>21.0</td>
            <td>30.5</td>
            <td>65.0</td>
            <td>54.5</td>
            <td>25.5</td>
            <td>31.0</td>
            <td>0.0</td>
            <td>6.0</td>
            <td>0.0</td>
            <td>0.0</td>
            <td><b>27.5</b></td>
            <td>31.1</td>
            <td>15.5</td>
            <td>2.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>10.0</td>
            <td>14.0</td>
            <td>5.5</td>
            <td>17.0</td>
            <td>30.5</td>
            <td>21.5</td>
            <td>0.0</td>
            <td>23.0</td>
            <td>45.5</td>
            <td>42.0</td>
            <td>24.5</td>
            <td>0.0</td>
            <td>2.0</td>
            <td>44.4</td>
            <td>20.5</td>
            <td>24.5</td>
            <td>24.5</td>
            <td>0.0</td>
            <td>7.5</td>
            <td>0.5</td>
            <td>1.5</td>
            <td>78.0</td>
            <td>0.5</td>
            <td>62.5</td>
            <td>40.5</td>
            <td>38.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/internlm/internlm-xcomposer2-vl-1_8b">
              <b>XComposer2-1.8b</b>
           </a>
          </td>  
            <td>23.5</td>
            <td>24.5</td>
            <td>23.0</td>
            <td>19.1</td>
            <td>16.4</td>
            <td>18.4</td>
            <td>10.0</td>
            <td>27.8</td>
            <td>27.5</td>
            <td>13.0</td>
            <td>12.0</td>
            <td>26.0</td>
            <td>55.5</td>
            <td>19.5</td>
            <td>33.5</td>
            <td>17.0</td>
            <td>54.0</td>
            <td>10.5</td>
            <td>1.5</td>
            <td>25.0</td>
            <td>59.5</td>
            <td>37.0</td>
            <td>25.5</td>
            <td>0.0</td>
            <td>24.4</td>
            <td>13.0</td>
            <td>68.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>59.0</td>
            <td>28.0</td>
            <td>34.0</td>
            <td>25.0</td>
            <td>28.5</td>
            <td>17.0</td>
            <td>17.5</td>
            <td>0.5</td>
            <td>29.5</td>
            <td>48.0</td>
            <td>6.0</td>
            <td>7.5</td>
            <td>33.2</td>
            <td>41.4</td>
            <td>7.0</td>
            <td>0.0</td>
            <td>15.5</td>
            <td>17.0</td>
            <td>28.0</td>
            <td>2.0</td>
            <td>29.0</td>
            <td>33.5</td>
            <td>9.0</td>
            <td>27.5</td>
            <td>11.5</td>
            <td>3.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/deepseek-ai/deepseek-vl-1.3b-base">
              <b>deepseek-vl-1.3b</b>
           </a>
          </td>    
            <td>23.2</td>
            <td>1.2</td>
            <td>27.5</td>
            <td>21.4</td>
            <td>23.1</td>
            <td>26.7</td>
            <td>30.0</td>
            <td>45.2</td>
            <td>54.8</td>
            <td>20.5</td>
            <td>25.0</td>
            <td>25.5</td>
            <td>46.0</td>
            <td>21.0</td>
            <td>30.5</td>
            <td>89.0</td>
            <td>0.0</td>
            <td>23.0</td>
            <td>31.0</td>
            <td>0.0</td>
            <td>1.0</td>
            <td>2.5</td>
            <td>0.0</td>
            <td>23.0</td>
            <td>26.4</td>
            <td>20.0</td>
            <td>1.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>6.5</td>
            <td>13.0</td>
            <td>3.5</td>
            <td>11.5</td>
            <td>33.0</td>
            <td>20.0</td>
            <td>0.5</td>
            <td>25.0</td>
            <td>44.5</td>
            <td>38.0</td>
            <td>24.0</td>
            <td>1.0</td>
            <td>0.0</td>
            <td><b>55.6</b></td>
            <td>31.0</td>
            <td>26.0</td>
            <td>31.0</td>
            <td>0.0</td>
            <td>19.5</td>
            <td>0.0</td>
            <td>1.5</td>
            <td>66.5</td>
            <td>3.0</td>
            <td>61.5</td>
            <td>45.5</td>
            <td>29.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://laion.ai/blog/open-flamingo-v2/">
              <b>flamingov2</b>
           </a>
          </td>    
            <td>22.3</td>
            <td>25.5</td>
            <td>25.8</td>
            <td>24.6</td>
            <td>21.6</td>
            <td>25.0</td>
            <td>28.2</td>
            <td>34.5</td>
            <td>49.0</td>
            <td>14.5</td>
            <td>19.0</td>
            <td>13.5</td>
            <td>22.5</td>
            <td>17.5</td>
            <td>26.0</td>
            <td>39.0</td>
            <td>49.0</td>
            <td>20.0</td>
            <td>27.5</td>
            <td>10.0</td>
            <td>13.5</td>
            <td>16.5</td>
            <td>30.0</td>
            <td>20.0</td>
            <td>18.7</td>
            <td>24.5</td>
            <td>22.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>25.0</td>
            <td>21.5</td>
            <td>25.5</td>
            <td>25.0</td>
            <td>14.5</td>
            <td>13.5</td>
            <td>15.5</td>
            <td>27.5</td>
            <td>4.0</td>
            <td>25.5</td>
            <td>23.0</td>
            <td>7.0</td>
            <td>22.1</td>
            <td>3.0</td>
            <td>1.5</td>
            <td>26.5</td>
            <td>22.0</td>
            <td>35.0</td>
            <td>17.0</td>
            <td>28.5</td>
            <td>20.5</td>
            <td>23.5</td>
            <td>11.5</td>
            <td>31.0</td>
            <td>25.0</td>
            <td>23.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://github.com/InternLM/InternLM-XComposer">
              <b>XComposer2</b>
           </a>   
          </td>
            <td>21.9</td>
            <td>24.0</td>
            <td>21.0</td>
            <td>10.8</td>
            <td>5.8</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>34.2</td>
            <td>24.0</td>
            <td>14.5</td>
            <td>2.5</td>
            <td>23.0</td>
            <td>63.5</td>
            <td>19.0</td>
            <td>26.0</td>
            <td>14.5</td>
            <td>31.0</td>
            <td>9.5</td>
            <td>28.5</td>
            <td>31.5</td>
            <td>59.5</td>
            <td>44.0</td>
            <td>30.0</td>
            <td>4.5</td>
            <td>15.5</td>
            <td>12.0</td>
            <td>66.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>55.0</td>
            <td>35.0</td>
            <td>42.5</td>
            <td>22.5</td>
            <td>2.5</td>
            <td>19.0</td>
            <td>20.0</td>
            <td>8.0</td>
            <td>15.5</td>
            <td>45.0</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>20.6</td>
            <td>0.0</td>
            <td>16.5</td>
            <td>0.0</td>
            <td>7.0</td>
            <td>0.0</td>
            <td>4.5</td>
            <td>0.0</td>
            <td>33.5</td>
            <td>63.0</td>
            <td>1.5</td>
            <td>38.5</td>
            <td>42.0</td>
            <td>33.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/Qwen/Qwen-7B-Chat">
              <b>qwen-chat</b>
           </a>   
          </td>
            <td>15.9</td>
            <td>20.5</td>
            <td>2.5</td>
            <td>13.3</td>
            <td>2.5</td>
            <td>9.9</td>
            <td>5.9</td>
            <td>31.2</td>
            <td>23.8</td>
            <td>10.5</td>
            <td>19.5</td>
            <td>12.5</td>
            <td>41.0</td>
            <td>5.5</td>
            <td>13.5</td>
            <td>29.5</td>
            <td>45.0</td>
            <td>3.0</td>
            <td>12.0</td>
            <td>10.0</td>
            <td>52.5</td>
            <td>18.5</td>
            <td>16.5</td>
            <td>2.5</td>
            <td>3.6</td>
            <td>5.5</td>
            <td>47.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>29.0</td>
            <td>23.0</td>
            <td>18.0</td>
            <td>6.0</td>
            <td>6.0</td>
            <td>6.0</td>
            <td>32.0</td>
            <td>9.0</td>
            <td>13.5</td>
            <td>17.0</td>
            <td>15.5</td>
            <td>3.5</td>
            <td>40.2</td>
            <td>15.8</td>
            <td>16.5</td>
            <td>16.5</td>
            <td>22.5</td>
            <td>17.5</td>
            <td>13.0</td>
            <td>14.5</td>
            <td>14.0</td>
            <td>8.0</td>
            <td>3.0</td>
            <td>8.5</td>
            <td>1.5</td>
            <td>0.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/HuggingFaceM4/idefics-9b-instruct">
              <b>idefics-9b-instruct</b>
           </a>   
          </td>
            <td>12.8</td>
            <td>10.8</td>
            <td>0.2</td>
            <td>0.2</td>
            <td>0.8</td>
            <td>0.0</td>
            <td>9.4</td>
            <td>23.0</td>
            <td>13.0</td>
            <td>2.5</td>
            <td>22.0</td>
            <td>14.0</td>
            <td>70.0</td>
            <td>3.0</td>
            <td>14.5</td>
            <td>40.5</td>
            <td>34.5</td>
            <td>3.5</td>
            <td>2.0</td>
            <td>4.0</td>
            <td>1.5</td>
            <td>20.0</td>
            <td>3.0</td>
            <td>15.5</td>
            <td>0.5</td>
            <td>3.0</td>
            <td>10.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>37.0</td>
            <td>27.5</td>
            <td>48.5</td>
            <td>23.0</td>
            <td>0.0</td>
            <td>5.5</td>
            <td>5.0</td>
            <td>3.0</td>
            <td>9.0</td>
            <td>16.0</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>6.5</td>
            <td>12.8</td>
            <td>1.0</td>
            <td>15.5</td>
            <td>10.5</td>
            <td>0.5</td>
            <td>36.5</td>
            <td>5.5</td>
            <td>2.5</td>
            <td>44.5</td>
            <td>1.5</td>
            <td>35.0</td>
            <td>0.0</td>
            <td>0.0</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/Qwen/Qwen-7B">
              <b>qwen-base</b>
           </a>   
          </td>
            <td>5.2</td>
            <td>9.2</td>
            <td>0.5</td>
            <td>5.7</td>
            <td>5.8</td>
            <td>0.5</td>
            <td>1.0</td>
            <td>5.0</td>
            <td>4.5</td>
            <td>0.0</td>
            <td>1.0</td>
            <td>0.0</td>
            <td>20.5</td>
            <td>0.0</td>
            <td>2.5</td>
            <td>1.0</td>
            <td>43.0</td>
            <td>1.0</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>4.5</td>
            <td>8.5</td>
            <td>0.5</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>7.5</td>
        </tr>
        <tr style="background-color: rgb(229, 237, 255);">
            <td></td>
            <td></td>
            <td>24.5</td>
            <td>8.0</td>
            <td>29.5</td>
            <td>5.0</td>
            <td>5.5</td>
            <td>6.5</td>
            <td>2.0</td>
            <td>2.0</td>
            <td>8.5</td>
            <td>11.5</td>
            <td>0.0</td>
            <td>0.0</td>
            <td>0.5</td>
            <td>5.3</td>
            <td>0.0</td>
            <td>0.5</td>
            <td>7.0</td>
            <td>0.0</td>
            <td>21.5</td>
            <td>0.0</td>
            <td>5.5</td>
            <td>2.5</td>
            <td>0.0</td>
            <td>0.5</td>
            <td>0.0</td>
            <td>0.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/THUDM/glm-4v-9b">
              <b>glm-4v-9b</b>
           </a>   
          </td>
            <td>27.0</td>
            <td>32.8</td>
            <td>16.0</td>
            <td>31.8</td>
            <td>8.7</td>
            <td>9.0</td>
            <td>4.7</td>
            <td>59.0</td>
            <td>55.8</td>
            <td>31.0</td>
            <td>7.5</td>
            <td>19.5</td>
            <td>82.0</td>
            <td>23.5</td>
            <td>24.5</td>
            <td>81.0</td>
            <td>67.0</td>
            <td>25.0</td>
            <td>30.0</td>
            <td>7.0</td>
            <td>59.5</td>
            <td>53.5</td>
            <td>10.5</td>
            <td>5.0</td>
            <td>25.9</td>
            <td>10.0</td>
            <td>76.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>55.5</td>
            <td>19.0</td>
            <td>34.0</td>
            <td>5.0</td>
            <td>11.5</td>
            <td>14.5</td>
            <td>26.0</td>
            <td>11.5</td>
            <td>35.5</td>
            <td>41.5</td>
            <td>16.0</td>
            <td>6.5</td>
            <td>25.1</td>
            <td>29.3</td>
            <td>9.0</td>
            <td>14.0</td>
            <td>14.5</td>
            <td>7.0</td>
            <td>0.5</td>
            <td>5.5</td>
            <td>27.0</td>
            <td>35.0</td>
            <td>7.5</td>
            <td>26.0</td>
            <td>48.5</td>
            <td>23.5</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/llava-hf/llava-v1.6-vicuna-7b-hf">
              <b>llava-next-vicuna_7b</b>
           </a>   
          </td>
            <td>22.2</td>
            <td>22.2</td>
            <td>9.2</td>
            <td>11.0</td>
            <td>9.1</td>
            <td>7.7</td>
            <td>10.5</td>
            <td>37.0</td>
            <td>23.2</td>
            <td>7.0</td>
            <td>16.5</td>
            <td>8.0</td>
            <td>66.0</td>
            <td>5.0</td>
            <td>23.5</td>
            <td>88.0</td>
            <td>42.5</td>
            <td>13.0</td>
            <td>14.5</td>
            <td>5.5</td>
            <td>51.0</td>
            <td>42.5</td>
            <td>9.5</td>
            <td>10.0</td>
            <td>17.1</td>
            <td>6.5</td>
            <td>66.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>50.5</td>
            <td>14.5</td>
            <td>38.0</td>
            <td>9.0</td>
            <td>9.5</td>
            <td>8.5</td>
            <td>31.0</td>
            <td>5.0</td>
            <td>28.5</td>
            <td>27.0</td>
            <td>8.5</td>
            <td>5.0</td>
            <td>22.6</td>
            <td>29.3</td>
            <td>6.5</td>
            <td>4.0</td>
            <td>4.0</td>
            <td>6.0</td>
            <td>8.0</td>
            <td>9.5</td>
            <td>32.5</td>
            <td>72.0</td>
            <td>1.0</td>
            <td>38.0</td>
            <td>42.0</td>
            <td>25.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5">
              <b>MiniCPM-Llama3-V-2-5</b>
           </a>   
          </td>
            <td>21.6</td>
            <td>41.1</td>
            <td>11.8</td>
            <td>13.2</td>
            <td>8.7</td>
            <td>5.0</td>
            <td>11.3</td>
            <td>47.8</td>
            <td>38.5</td>
            <td>7.0</td>
            <td>3.0</td>
            <td>6.5</td>
            <td>77.0</td>
            <td>7.5</td>
            <td>18.5</td>
            <td>41.5</td>
            <td>41.5</td>
            <td>10.0</td>
            <td>5.0</td>
            <td>0.5</td>
            <td>70.5</td>
            <td>51.0</td>
            <td>13.5</td>
            <td>4.5</td>
            <td>17.6</td>
            <td>5.0</td>
            <td>83.5</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>46.0</td>
            <td>24.5</td>
            <td>26.0</td>
            <td>4.5</td>
            <td>20.5</td>
            <td>12.0</td>
            <td>43.0</td>
            <td>0.0</td>
            <td>25.0</td>
            <td>44.5</td>
            <td>0.0</td>
            <td>1.5</td>
            <td>34.2</td>
            <td>38.3</td>
            <td>6.0</td>
            <td>8.5</td>
            <td>5.5</td>
            <td>9.5</td>
            <td>20.0</td>
            <td>4.5</td>
            <td>24.5</td>
            <td>14.5</td>
            <td>0.5</td>
            <td>22.0</td>
            <td>32.5</td>
            <td>15.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/liuhaotian/llava-v1.5-7b">
              <b>LLaVA-v1.5-7B</b>
           </a> 
          </td>
            <td>19.2</td>
            <td>14.1</td>
            <td>4.2</td>
            <td>13.7</td>
            <td>5.8</td>
            <td>1.9</td>
            <td>6.9</td>
            <td>27.3</td>
            <td>35.0</td>
            <td>6.5</td>
            <td>12.5</td>
            <td>12.5</td>
            <td>53.0</td>
            <td>10.0</td>
            <td>25.5</td>
            <td>66.5</td>
            <td>43.0</td>
            <td>19.0</td>
            <td>3.5</td>
            <td>2.5</td>
            <td>23.5</td>
            <td>36.5</td>
            <td>12.0</td>
            <td>16.5</td>
            <td>6.7</td>
            <td>7.0</td>
            <td>28.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>24.5</td>
            <td>17.5</td>
            <td>40.0</td>
            <td>15.0</td>
            <td>21.5</td>
            <td>4.0</td>
            <td>26.0</td>
            <td>7.5</td>
            <td>26.5</td>
            <td>17.5</td>
            <td>5.0</td>
            <td>4.5</td>
            <td>25.6</td>
            <td>27.1</td>
            <td>8.5</td>
            <td>8.0</td>
            <td>4.0</td>
            <td>6.0</td>
            <td>6.0</td>
            <td>14.5</td>
            <td>29.5</td>
            <td>66.0</td>
            <td>2.0</td>
            <td>35.0</td>
            <td>34.5</td>
            <td>28.5</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/Lin-Chen/ShareGPT4V-7B">
              <b>ShareGPT4V-7B</b>
          </td>
            <td>18.5</td>
            <td>16.4</td>
            <td>5.0</td>
            <td>10.8</td>
            <td>6.2</td>
            <td>9.0</td>
            <td>2.7</td>
            <td>34.2</td>
            <td>28.5</td>
            <td>4.5</td>
            <td>10.5</td>
            <td>3.5</td>
            <td>57.0</td>
            <td>4.0</td>
            <td>12.5</td>
            <td>55.5</td>
            <td>44.5</td>
            <td>13.5</td>
            <td>5.0</td>
            <td>5.0</td>
            <td>26.0</td>
            <td>38.0</td>
            <td>14.0</td>
            <td>15.5</td>
            <td>10.9</td>
            <td>6.0</td>
            <td>25.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>26.5</td>
            <td>19.0</td>
            <td>42.0</td>
            <td>7.5</td>
            <td>14.0</td>
            <td>7.5</td>
            <td>31.5</td>
            <td>7.0</td>
            <td>29.0</td>
            <td>18.0</td>
            <td>5.0</td>
            <td>1.5</td>
            <td>28.1</td>
            <td>23.3</td>
            <td>9.5</td>
            <td>3.0</td>
            <td>7.0</td>
            <td>6.0</td>
            <td>2.0</td>
            <td>8.0</td>
            <td>27.5</td>
            <td>65.5</td>
            <td>0.0</td>
            <td>44.0</td>
            <td>36.5</td>
            <td>31.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/Lin-Chen/ShareCaptioner">
              <b>SharedCaptioner</b>
           </a>
          </td>
            <td>16.1</td>
            <td>20.7</td>
            <td>22.2</td>
            <td>27.2</td>
            <td>10.2</td>
            <td>9.1</td>
            <td>21.0</td>
            <td>39.5</td>
            <td>37.0</td>
            <td>7.0</td>
            <td>5.0</td>
            <td>6.0</td>
            <td>47.0</td>
            <td>5.0</td>
            <td>17.0</td>
            <td>25.0</td>
            <td>35.5</td>
            <td>12.5</td>
            <td>13.0</td>
            <td>5.5</td>
            <td>14.5</td>
            <td>4.5</td>
            <td>3.0</td>
            <td>6.0</td>
            <td>18.1</td>
            <td>5.5</td>
            <td>21.5</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>17.0</td>
            <td>22.5</td>
            <td>18.5</td>
            <td>12.0</td>
            <td>14.5</td>
            <td>11.0</td>
            <td>23.5</td>
            <td>7.0</td>
            <td>25.5</td>
            <td>22.0</td>
            <td>5.5</td>
            <td>2.0</td>
            <td>16.1</td>
            <td>43.6</td>
            <td>9.0</td>
            <td>2.5</td>
            <td>1.5</td>
            <td>1.5</td>
            <td>5.5</td>
            <td>8.0</td>
            <td>26.5</td>
            <td>47.0</td>
            <td>2.0</td>
            <td>28.0</td>
            <td>16.5</td>
            <td>9.0</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
          <td style="text-align: left;">
            <a href="https://huggingface.co/echo840/Monkey-Chat">
              <b>Monkey-Chat</b>
           </a> 
          </td>
            <td>13.7</td>
            <td>8.4</td>
            <td>8.0</td>
            <td>5.9</td>
            <td>9.2</td>
            <td>6.7</td>
            <td>8.1</td>
            <td>23.5</td>
            <td>25.3</td>
            <td>4.5</td>
            <td>6.0</td>
            <td>1.5</td>
            <td>34.5</td>
            <td>2.0</td>
            <td>9.0</td>
            <td>40.5</td>
            <td>40.5</td>
            <td>12.0</td>
            <td>2.5</td>
            <td>6.5</td>
            <td>16.5</td>
            <td>14.5</td>
            <td>10.0</td>
            <td>12.5</td>
            <td>18.1</td>
            <td>6.5</td>
            <td>19.5</td>
        </tr>
        <tr style="background-color: rgb(224, 243, 224);">
            <td></td>
            <td></td>
            <td>10.0</td>
            <td>8.5</td>
            <td>17.0</td>
            <td>8.0</td>
            <td>13.0</td>
            <td>7.5</td>
            <td>15.5</td>
            <td>7.0</td>
            <td>27.5</td>
            <td>17.0</td>
            <td>5.5</td>
            <td>3.0</td>
            <td>10.6</td>
            <td>22.6</td>
            <td>9.0</td>
            <td>5.5</td>
            <td>8.0</td>
            <td>6.0</td>
            <td>5.5</td>
            <td>7.5</td>
            <td>34.5</td>
            <td>51.0</td>
            <td>1.5</td>
            <td>17.0</td>
            <td>36.0</td>
            <td>8.5</td>
        </tr>
      </table>  
        </div>
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Performance across Image Relationships</h2>
        <div class="content has-text-justified">
          <p>We find that models exhibit varying capabilities across different image relationships. More detailed visualizations can be found in the paper. 
            In general, LVLMs excel at understanding semantic content in multi-image scenarios, perform moderately in temporal tasks, and obtain the worst performance in comprehending spatial relationships in multi-image contexts.
          </p>
          <p>
            <b>1) Semantic Relationships</b>, models generally perform well on multi-image semantic tasks involving low-level relationships. However, they struggle with high-level tasks, for subjective tasks such as Causality Reasoning and Emotion Recognition, which require the identification and reasoning of implicit visual information, highlighting a gap between model performance and human visual cognition. As for objective tasks such retrieval tasks, most models fail to tackle them. 
          </p>
          <p>
            <b>2) In temporal relationships</b>, models can handle discrete and continuous temporal relationships relatively well but show mediocre performance on reasoning-intensive multi-image tasks. For instance, in sorting tasks, GPT4o achieves only 28% and 21.5% accuracy in temporal ordering and visual ordering tasks, respectively.
          </p>
          <p>
            <b>3) In spatial relationships</b>, we find that models struggle with understanding both 2D and 3D positional relations. This is consistent with the observation in the previous single-image evaluation benchmark where they find that LVLMs fall short in localization and detection tasks requiring spatial reasoning. The tasks involving spatial relationships in MMIU become more challenging because models need to gather spatial information in multiple images and to reason.
            </p>
        </div>
        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
                <div class="content has-text-centered">
                  <img src="static/images/meta.jpg" alt="Performance across Image Relationships" width="90%">
                  <p>
                    (a): The average performance comparison of 24 LVLMs on three main image relationships.
                    (b): The average performance comparison of representative models such as GPT4o on seven specific image relationships. </p>
                </div>
            
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Taskonomy Analysis</h2>
        <div class="content has-text-justified">
          <p>
            Task map is an effective tool for multi-task analysis. Thanks to extensive coverage of multi-image tasks in MMIU, we build a task map to analyze the relationships between different tasks, allowing us to identify in- and out-of-domain tasks for current LVLMs.
            Following <a href="https://github.com/OpenGVLab/MMT-Bench">MMT-Bench</a>, we use QwenVL-chat to construct a task map where the distance between two tasks is given. Detailed construction process of the task map can be found in the paper.
          </p>
          <p>
            <b>Tasks involving recognition or captioning are in-domain tasks</b> which can be handled by most current multimodal large models. For multi-image tasks, models generally struggle to achieve satisfactory results, obtaining good performance on a limited number of tasks. Specifically, for tasks in clusters 7, 8, and some tasks in cluster 2, which involve recognition or captioning (e.g., video captioning, action recognition), models perform relatively well. This is because these multi-image tasks focus on overall image perception, requiring less comparison and reasoning between images. 
          </p>
          <p>
            <b>Tasks involving temporal ordering and 3D spatial reasoning are out-of-domain Tasks</b> where most models perform poorly. Specifically, models struggle with tasks in clusters 4, 5, and 6. Clusters 4 and 6 involve modelling semantic relationships or sequential order among multiple images, requiring memorizing detailed long-context content and strong reasoning skills. Most LVLMs underperform on these tasks such as temporal ordering tasks.
            Tasks in cluster 5 pertain to 3D visual tasks such as 3D detection and tracking. This may be due to the lack of 3D vision-language data in training LVLMs.
          </p>
        </div>
        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
                <div class="content has-text-centered">
                  <img src="static/images/task_map.jpg" alt="error distribution" width="100%">
                  <p> (a): Visualization of task maps and hierarchical clustering along with the task map. (b): Visualization of model performance across various tasks. Different colors represent the respective categories formed through clustering, arranged sequentially from left to right, starting from the first category to the eighth. Notice that although InternVL1.5-chat supports multiple image inputs, its training phase did not incorporate multi-image data. </p>
                </div>
            
          </div>
        </div>
       
        <!-- <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_distribution_1.Jpeg" alt="algebraic reasoning" width="45%"/>
              <p> Error distribution over 150 annotated GPT-4V errors.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_case_main_text_1_1.Jpeg" alt="arithmetic reasoning" width="45%"/>
              <p> A basic perceptual error, easy for humans but challenging for GPT-4V.</p>
            </div>
          </div>
        </div> -->
      </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Task Learning Difficulty</h2>
        <div class="content has-text-justified">
          <p>
            We analyze task learning difficulty by SFT with all evaluation samples in MMIU being instruction tuning data. 
            In this way, we can identify tasks which cannot be improved by simple SFT. 
            To this end, we fine-tune QwenVL-chat on each task for 20 epochs and obtain the accuracy of QwenVL-chat on each task, denoted as <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>SFT</sub></span>. The lower accuracy reflects the larger fitting difficulty of the task. Meanwhile, we also obtain the average accuracy of all tested models on each task, denoted as <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>Model</sub></span>. This accuracy reflects the difficulty current models face in handling these tasks.
          </p>
          <p>
            We find that the Spearman correlation coefficient between <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>SFT</sub></span> and <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>Model</sub></span> is 0.66, indicating a high correlation. This suggests that both measures can reflect task difficulty to some extent. More importantly, we need to focus on tasks where both <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>SFT</sub></span> and <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>Model</sub></span> are low. A low <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>SFT</sub></span> indicates that the task is difficult to overfit even with SFT, suggesting that additional pre-training data or training techniques might be necessary. These tasks include 1) Ordering and retrieval tasks, which require strong memory and reasoning abilities‚Äîcapabilities that are generally weak in large multimodal models; 2) Tasks involving a large number of images, such as EVQA, MEV, and GNAP, require models to support longer context lengths and possess strong memory capabilities. This indicates that future multimodal model designs should consider the ability to handle long contexts and emphasize the inclusion of multi-image data during the pre-training phase.

            </p>
        </div>
        <div class="content has-text-centered">
          <img src="static/images/Qwen_acc.jpeg" alt="error distribution" width="60%">
          <p> The performance of <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>Model</sub></span> and <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>SFT</sub></span> across different tasks, sorted by <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>Model</sub></span> in descending order, with <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>SFT</sub></span> scaled to the same magnitude as <span class="math inline"><em>A</em><em>c</em><em>c</em><sub>Model</sub></span> for easy comparison.</p>
        </div>
        <!-- <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_distribution_1.Jpeg" alt="algebraic reasoning" width="45%"/>
              <p> Error distribution over 150 annotated GPT-4V errors.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error_case_main_text_1_1.Jpeg" alt="arithmetic reasoning" width="45%"/>
              <p> A basic perceptual error, easy for humans but challenging for GPT-4V.</p>
            </div>
          </div>
        </div> -->
      </div>
    </div>
  
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="examples">Error Examples</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_2d.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_3d.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_continuous.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_discrete.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_highlevelobj.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_highlevelsub.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/error/crop_error_case_lowlevel.png" alt="grade-lv" width="60%"/>
            </div>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>
<!-- @PAN TODO: bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @misc{meng2024mmiumultimodalmultiimageunderstanding,
        title={MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models}, 
        author={Fanqing Meng and Jin Wang and Chuanhao Li and Quanfeng Lu and Hao Tian and Jiaqi Liao and Xizhou Zhu and Jifeng Dai and Yu Qiao and Ping Luo and Kaipeng Zhang and Wenqi Shao},
        year={2024},
        eprint={2408.02718},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2408.02718}, 
  }
</code></pre>
  </div>
</section>

<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://github.com/OpenGVLab/MMT-Bench">MMT-Bench</a>, <a href="https://mmmu-benchmark.github.io/">MMMU</a>, <a href="https://mathvista.github.io/">MathVista</a> and <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->

</footer>
<script>
  function changeButtonText() {
    var button = document.getElementById('toggleButton');
    if (button.innerHTML.includes("Validation Set Leaderboard")) {
      button.innerHTML = "<b style='font-size: larger;'>Test Set Leaderboard</b> (Click to Switch)";
    } else {
      button.innerHTML = "<b style='font-size: larger;'>Validation Set Leaderboard</b> (Click to Switch)";
    }
  }
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');

    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

function sortTable(table, column, type, asc) {
    var tbody = table.tBodies[0];
    var rows = Array.from(tbody.rows);

    rows.sort(function(a, b) {
        var valA = a.cells[column].textContent;
        var valB = b.cells[column].textContent;

        if (type === 'number') {
            valA = parseFloat(valA);
            valB = parseFloat(valB);
        }

        return asc ? valA - valB : valB - valA;
    });

    rows.forEach(row => tbody.appendChild(row));
}

  // ÂàáÊç¢Ë°®Ê†ºÁöÑÂáΩÊï∞
  function toggleTables () {
      var table1 = document.getElementById('table1');
      var table2 = document.getElementById('table2');
      table1.classList.toggle('hidden');
      table2.classList.toggle('hidden');
  }

  document.getElementById('toggleButton').addEventListener('click', toggleTables);
  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'GPT-4V',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 // ËÆæÁΩÆXËΩ¥Â≠ó‰ΩìÂ§ßÂ∞è
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 // ËÆæÁΩÆÊ†áÁ≠æÊñáÂ≠óÂ§ßÂ∞è
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });
  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Other " chart
    const data_Other   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' ‚Üë';
  }
  .desc::after {
      content: ' ‚Üì';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* Èº†Ê†áÊÇ¨ÂÅúÊó∂ÁöÑÈò¥ÂΩ±ÊïàÊûú */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>
</body>
</html>
